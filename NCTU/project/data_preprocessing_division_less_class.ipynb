{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL VARIABLES\n",
    "\n",
    "path_train_images = \"data/train2014/\"\n",
    "path_train_labels = \"data/coco/labels/train2014/\"\n",
    "path_val_images = \"data/val2014/\"\n",
    "path_val_labels = \"data/coco/labels/val2014/\"\n",
    "\n",
    "MAX_file_name_train = 581921\n",
    "MIN_file_name_train = 9\n",
    "MAX_file_name_val = 581929\n",
    "MIN_file_name_val = 42\n",
    "nb_file_train = 82783\n",
    "nb_file_val = 40504\n",
    "\n",
    "nb_labels=80\n",
    "\n",
    "nb_train = 1800\n",
    "nb_val = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILS\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "def get_fname(file_nb):\n",
    "    return (12-len(str(file_nb)))*'0'+str(file_nb)\n",
    "\n",
    "def pair_exist(file_nb,val=False):    #val=False : check on training set | val=True : check on val set\n",
    "    exist=False\n",
    "    if(not val):\n",
    "        t1 = os.path.exists(path_train_images+\"COCO_train2014_\"+get_fname(file_nb)+\".jpg\")\n",
    "        t2 = os.path.exists(path_train_labels+\"COCO_train2014_\"+get_fname(file_nb)+\".txt\")\n",
    "        if(t1 and t2):\n",
    "            exist=True\n",
    "    else:\n",
    "        t1 = os.path.exists(path_val_images+\"COCO_val2014_\"+get_fname(file_nb)+\".jpg\")\n",
    "        t2 = os.path.exists(path_val_labels+\"COCO_val2014_\"+get_fname(file_nb)+\".txt\")\n",
    "        if(t1 and t2):\n",
    "            exist=True\n",
    "    return exist\n",
    "\n",
    "def print_labels(nbl,percl):\n",
    "    print(\"Label  |  Number  |  Percentage\")\n",
    "    print(\"_______________________________\")\n",
    "    for i in range(len(nbl)):\n",
    "        print(\" \"+(2-len(str(i)))*'0'+str(i)+\"    |  \"+str(nbl[i])+(6-len(str(nbl[i])))*' '+\"  |  \"+str(format(percl[i]*100,'0.3f'))+\"%\" )\n",
    "    total=np.sum(nbl)\n",
    "    totalp=np.sum(percl)\n",
    "    print(\"Total  |  \"+str(total)+(8-len(str(total)))*' '+\"|  \"+str(totalp*100)+\"%\")\n",
    "    \n",
    "\n",
    "def get_all_labels(val=False):\n",
    "    if (not val):\n",
    "        path=path_train_labels\n",
    "        mini=MIN_file_name_train\n",
    "        maxi=MAX_file_name_train\n",
    "        name=\"COCO_train2014_\"\n",
    "    else:\n",
    "        path=path_val_labels\n",
    "        mini=MIN_file_name_val\n",
    "        maxi=MAX_file_name_val\n",
    "        name=\"COCO_val2014_\"\n",
    "    total=0\n",
    "    nbtotfile=0\n",
    "    all_labels_number=np.zeros((nb_labels),dtype='int32') #use int16 if not many labels\n",
    "    for file_nb in range(mini,maxi+1):\n",
    "        if(pair_exist(file_nb,val=val)):\n",
    "            f=open(path+name+get_fname(file_nb)+\".txt\",\"r\")\n",
    "            Lines=f.readlines()\n",
    "            f.close()\n",
    "            for line in Lines:\n",
    "                all_labels_number[int(line[0:len(str(nb_labels))])]+=1\n",
    "                total+=1\n",
    "            nbtotfile+=1\n",
    "    all_labels_percentage=np.copy(all_labels_number)\n",
    "    all_labels_percentage=all_labels_percentage.astype('float64')\n",
    "    all_labels_percentage/=total\n",
    "    \n",
    "    \n",
    "    return all_labels_number, all_labels_percentage, nbtotfile\n",
    "\n",
    "\n",
    "def create_dir():\n",
    "    try:\n",
    "        os.mkdir(\"data_divided\")\n",
    "    except:\n",
    "        print(\"data_divided already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/images\")\n",
    "    except:\n",
    "        print(\"data_divided/images already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/labels\")\n",
    "    except:\n",
    "        print(\"data_divided/labels already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/images/train2014\")\n",
    "    except:\n",
    "        print(\"data_divided/images/train2014 already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/images/val2014\")\n",
    "    except:\n",
    "        print(\"data_divided/images/val2014 already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/labels/train2014\")\n",
    "    except:\n",
    "        print(\"data_divided/labels/train2014 already exist\")\n",
    "    try:\n",
    "        os.mkdir(\"data_divided/labels/val2014\")\n",
    "    except:\n",
    "        print(\"data_divided/labels/val2014 already exist\")\n",
    "    \n",
    "    #create logs\n",
    "    f=open(\"data_divided/logs\",\"w\")\n",
    "    currentDT = datetime.datetime.now()\n",
    "    f.write(\"logs version from \"+str(currentDT)+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def divide_dataset(nbl,percl,val=False):\n",
    "    if (not val):\n",
    "        path=path_train_labels\n",
    "        nbtot=nb_train\n",
    "        nbtotfile=nb_file_train\n",
    "        mini=MIN_file_name_train\n",
    "        maxi=MAX_file_name_train\n",
    "        name=\"COCO_train2014_\"\n",
    "    else:\n",
    "        path=path_val_labels\n",
    "        nbtot=nb_val\n",
    "        nbtotfile=nb_file_val\n",
    "        mini=MIN_file_name_val\n",
    "        maxi=MAX_file_name_val\n",
    "        name=\"COCO_val2014_\"\n",
    "        \n",
    "    #optimal_nb=percl*float(nbtot)\n",
    "    optimal_nb=nbl.astype('float64')*float(nbtot)/float(nbtotfile)\n",
    "    actual_nb=np.zeros((nb_labels))\n",
    "    filenb_chosen=[]\n",
    "    file_nb=mini\n",
    "    while(len(filenb_chosen)<nbtot):\n",
    "                \n",
    "\n",
    "        if (pair_exist(file_nb,val=val) and (file_nb not in filenb_chosen) ):\n",
    "            diff=optimal_nb-actual_nb\n",
    "            label_int=np.max(diff)\n",
    "            piv=0\n",
    "            for i in range(0,len(actual_nb)):\n",
    "                if(diff[i]==label_int):\n",
    "                    piv=i\n",
    "            label_int=piv\n",
    "        \n",
    "            f=open(path+name+get_fname(file_nb)+\".txt\",\"r\")\n",
    "            Lines=f.readlines()\n",
    "            f.close()\n",
    "            file_label=[]\n",
    "            for line in Lines:\n",
    "                file_label.append(int(line[0:len(str(nb_labels))]))\n",
    "                \n",
    "            if (label_int in file_label):\n",
    "                for i in file_label:\n",
    "                    actual_nb[i]+=1\n",
    "                filenb_chosen.append(file_nb)\n",
    "        \n",
    "        file_nb+=1\n",
    "        if (file_nb>maxi):\n",
    "            file_nb=mini\n",
    "    \n",
    "    return filenb_chosen, optimal_nb, actual_nb\n",
    "          \n",
    "\n",
    "def create_divide_dataset(filechosen,val=False):\n",
    "    if (not val):\n",
    "        pathl=path_train_labels\n",
    "        pathi=path_train_images\n",
    "        pathcopy=\"train2014/\"\n",
    "        mini=MIN_file_name_train\n",
    "        maxi=MAX_file_name_train\n",
    "        name=\"COCO_train2014_\"\n",
    "        f=open(\"data_divided/logs\",\"a\")\n",
    "        f.write(\"\\n\\ntrain set - \"+str(nb_train)+\" files chosen :\\n\\n\")\n",
    "        f.close()\n",
    "    else:\n",
    "        pathl=path_val_labels\n",
    "        pathi=path_val_images\n",
    "        pathcopy=\"val2014/\"\n",
    "        mini=MIN_file_name_val\n",
    "        maxi=MAX_file_name_val\n",
    "        name=\"COCO_val2014_\"\n",
    "        f=open(\"data_divided/logs\",\"a\")\n",
    "        f.write(\"\\n\\nval set - \"+str(nb_val)+\" files chosen :\\n\\n\")\n",
    "        f.close()\n",
    "    \n",
    "    for file_nb in range(mini,maxi+1):\n",
    "        if (pair_exist(file_nb,val=val)):\n",
    "            if(file_nb in filechosen):\n",
    "                shutil.copy(pathi+name+get_fname(file_nb)+\".jpg\",\"data_divided/images/\"+pathcopy+name+get_fname(file_nb)+\".jpg\")\n",
    "                shutil.copy(pathl+name+get_fname(file_nb)+\".txt\",\"data_divided/labels/\"+pathcopy+name+get_fname(file_nb)+\".txt\")\n",
    "                cho=\"O\"\n",
    "            else:\n",
    "                cho=\"X\"\n",
    "            \n",
    "            #fill logs\n",
    "            fr=open(pathl+name+get_fname(file_nb)+\".txt\",\"r\")\n",
    "            Lines=fr.readlines()\n",
    "            fr.close()\n",
    "            file_label=[]\n",
    "            for line in Lines:\n",
    "                file_label.append(int(line[0:len(str(nb_labels))]))\n",
    "            f=open(\"data_divided/logs\",\"a\")\n",
    "            f.write(cho+\" - \"+name+get_fname(file_nb)+\"  Labels : \")\n",
    "            \n",
    "            for i in range(len(file_label)-1):\n",
    "                f.write(str(file_label[i])+\", \")\n",
    "            f.write(str(file_label[len(file_label)-1])+\"\\n\")\n",
    "            f.close()\n",
    "                \n",
    "        \n",
    "\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#get full training labels\n",
    "\n",
    "all_labels_number,all_labels_percentage,nbtotfile=get_all_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82081\n"
     ]
    }
   ],
   "source": [
    "#update nb of file\n",
    "nb_file_train=nbtotfile\n",
    "print(nb_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  181681  |  30.388%\n",
      " 01    |  4912    |  0.822%\n",
      " 02    |  30551   |  5.110%\n",
      " 03    |  5972    |  0.999%\n",
      " 04    |  3828    |  0.640%\n",
      " 05    |  4321    |  0.723%\n",
      " 06    |  3158    |  0.528%\n",
      " 07    |  7047    |  1.179%\n",
      " 08    |  7457    |  1.247%\n",
      " 09    |  9125    |  1.526%\n",
      " 10    |  1316    |  0.220%\n",
      " 11    |  1372    |  0.229%\n",
      " 12    |  833     |  0.139%\n",
      " 13    |  6741    |  1.128%\n",
      " 14    |  7117    |  1.190%\n",
      " 15    |  3299    |  0.552%\n",
      " 16    |  3767    |  0.630%\n",
      " 17    |  4652    |  0.778%\n",
      " 18    |  6458    |  1.080%\n",
      " 19    |  5598    |  0.936%\n",
      " 20    |  3880    |  0.649%\n",
      " 21    |  903     |  0.151%\n",
      " 22    |  3658    |  0.612%\n",
      " 23    |  3593    |  0.601%\n",
      " 24    |  6194    |  1.036%\n",
      " 25    |  7753    |  1.297%\n",
      " 26    |  8769    |  1.467%\n",
      " 27    |  4466    |  0.747%\n",
      " 28    |  4192    |  0.701%\n",
      " 29    |  1861    |  0.311%\n",
      " 30    |  4684    |  0.783%\n",
      " 31    |  1957    |  0.327%\n",
      " 32    |  4361    |  0.729%\n",
      " 33    |  6359    |  1.064%\n",
      " 34    |  2398    |  0.401%\n",
      " 35    |  2689    |  0.450%\n",
      " 36    |  4010    |  0.671%\n",
      " 37    |  4135    |  0.692%\n",
      " 38    |  3406    |  0.570%\n",
      " 39    |  16801   |  2.810%\n",
      " 40    |  5560    |  0.930%\n",
      " 41    |  14459   |  2.418%\n",
      " 42    |  3914    |  0.655%\n",
      " 43    |  5530    |  0.925%\n",
      " 44    |  4282    |  0.716%\n",
      " 45    |  10043   |  1.680%\n",
      " 46    |  6711    |  1.122%\n",
      " 47    |  4251    |  0.711%\n",
      " 48    |  3076    |  0.514%\n",
      " 49    |  4530    |  0.758%\n",
      " 50    |  4894    |  0.819%\n",
      " 51    |  5477    |  0.916%\n",
      " 52    |  1999    |  0.334%\n",
      " 53    |  3994    |  0.668%\n",
      " 54    |  4859    |  0.813%\n",
      " 55    |  4509    |  0.754%\n",
      " 56    |  26857   |  4.492%\n",
      " 57    |  4113    |  0.688%\n",
      " 58    |  5904    |  0.988%\n",
      " 59    |  2905    |  0.486%\n",
      " 60    |  11152   |  1.865%\n",
      " 61    |  2866    |  0.479%\n",
      " 62    |  4034    |  0.675%\n",
      " 63    |  3409    |  0.570%\n",
      " 64    |  1517    |  0.254%\n",
      " 65    |  4120    |  0.689%\n",
      " 66    |  1979    |  0.331%\n",
      " 67    |  4451    |  0.744%\n",
      " 68    |  1188    |  0.199%\n",
      " 69    |  2302    |  0.385%\n",
      " 70    |  156     |  0.026%\n",
      " 71    |  3933    |  0.658%\n",
      " 72    |  1872    |  0.313%\n",
      " 73    |  16864   |  2.821%\n",
      " 74    |  4316    |  0.722%\n",
      " 75    |  4600    |  0.769%\n",
      " 76    |  1059    |  0.177%\n",
      " 77    |  3397    |  0.568%\n",
      " 78    |  135     |  0.023%\n",
      " 79    |  1372    |  0.229%\n",
      "Total  |  597863  |  100.0%\n"
     ]
    }
   ],
   "source": [
    "#print full training labels\n",
    "print_labels(all_labels_number,all_labels_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create directory for new dataset\n",
    "create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for train dataset : chose file number for balance reduced dataset\n",
    "\n",
    "divide_file_number_train, divide_optimal_labels_train, divide_chosen_labels_train = divide_dataset(all_labels_number,all_labels_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_op=np.sum(divide_optimal_labels_train)\n",
    "tot_cho=np.sum(divide_chosen_labels_train)\n",
    "opti_perc=divide_optimal_labels_train/tot_op\n",
    "cho_perc=np.copy(divide_chosen_labels_train)\n",
    "cho_perc=cho_perc.astype(\"float64\")\n",
    "cho_perc/=tot_cho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  3984.1839158879643  |  30.388%\n",
      " 01    |  107.71798589198475  |  0.822%\n",
      " 02    |  669.9699077740281  |  5.110%\n",
      " 03    |  130.96331672372412  |  0.999%\n",
      " 04    |  83.94634568292297  |  0.640%\n",
      " 05    |  94.75761747542062  |  0.723%\n",
      " 06    |  69.2535422326726  |  0.528%\n",
      " 07    |  154.53759091629001  |  1.179%\n",
      " 08    |  163.5287094455477  |  1.247%\n",
      " 09    |  200.10721116945456  |  1.526%\n",
      " 10    |  28.859297523178324  |  0.220%\n",
      " 11    |  30.087352736930594  |  0.229%\n",
      " 12    |  18.267321304565  |  0.139%\n",
      " 13    |  147.8271463554294  |  1.128%\n",
      " 14    |  156.07265993348034  |  1.190%\n",
      " 15    |  72.34560982444171  |  0.552%\n",
      " 16    |  82.60864268222853  |  0.630%\n",
      " 17    |  102.01630097099206  |  0.778%\n",
      " 18    |  141.62108161450274  |  1.080%\n",
      " 19    |  122.76166226045004  |  0.936%\n",
      " 20    |  85.08668266712151  |  0.649%\n",
      " 21    |  19.80239032175534  |  0.151%\n",
      " 22    |  80.21832092688929  |  0.612%\n",
      " 23    |  78.79289969664113  |  0.601%\n",
      " 24    |  135.83167846395634  |  1.036%\n",
      " 25    |  170.01985843252396  |  1.297%\n",
      " 26    |  192.3002887391723  |  1.467%\n",
      " 27    |  97.93740329674345  |  0.747%\n",
      " 28    |  91.92870457231271  |  0.701%\n",
      " 29    |  40.81090629987452  |  0.311%\n",
      " 30    |  102.71804680742194  |  0.783%\n",
      " 31    |  42.91614380916412  |  0.327%\n",
      " 32    |  95.63479977095795  |  0.729%\n",
      " 33    |  139.45005543304785  |  1.064%\n",
      " 34    |  52.587078617463234  |  0.401%\n",
      " 35    |  58.96857981749735  |  0.450%\n",
      " 36    |  87.93752512761785  |  0.671%\n",
      " 37    |  90.67871980117201  |  0.692%\n",
      " 38    |  74.69207246500409  |  0.570%\n",
      " 39    |  368.43849368306917  |  2.810%\n",
      " 40    |  121.92833907968958  |  0.930%\n",
      " 41    |  317.0794702793582  |  2.418%\n",
      " 42    |  85.83228761832824  |  0.655%\n",
      " 43    |  121.27045235803658  |  0.925%\n",
      " 44    |  93.90236473727172  |  0.716%\n",
      " 45    |  220.2385448520364  |  1.680%\n",
      " 46    |  147.1692596337764  |  1.122%\n",
      " 47    |  93.22254845823028  |  0.711%\n",
      " 48    |  67.45531852682107  |  0.514%\n",
      " 49    |  99.3408949696032  |  0.758%\n",
      " 50    |  107.32325385899294  |  0.819%\n",
      " 51    |  120.1081858164496  |  0.916%\n",
      " 52    |  43.83718521947832  |  0.334%\n",
      " 53    |  87.58665220940291  |  0.668%\n",
      " 54    |  106.55571935039778  |  0.813%\n",
      " 55    |  98.88037426444609  |  0.754%\n",
      " 56    |  588.9621227811552  |  4.492%\n",
      " 57    |  90.19626953862648  |  0.688%\n",
      " 58    |  129.47210682131066  |  0.988%\n",
      " 59    |  63.70536421339896  |  0.486%\n",
      " 60    |  244.55842399580902  |  1.865%\n",
      " 61    |  62.85011147525006  |  0.479%\n",
      " 62    |  88.46383450494024  |  0.675%\n",
      " 63    |  74.75786113716939  |  0.570%\n",
      " 64    |  33.267138558253436  |  0.254%\n",
      " 65    |  90.34977644034551  |  0.689%\n",
      " 66    |  43.39859407170965  |  0.331%\n",
      " 67    |  97.60845993591695  |  0.744%\n",
      " 68    |  26.05231417745885  |  0.199%\n",
      " 69    |  50.48184110817363  |  0.385%\n",
      " 70    |  3.4210109525956067  |  0.026%\n",
      " 71    |  86.24894920870847  |  0.658%\n",
      " 72    |  41.05213143114728  |  0.313%\n",
      " 73    |  369.82005579854047  |  2.821%\n",
      " 74    |  94.64796968847845  |  0.722%\n",
      " 75    |  100.87596398679354  |  0.769%\n",
      " 76    |  23.223401274350945  |  0.177%\n",
      " 77    |  74.49470644850818  |  0.568%\n",
      " 78    |  2.9604902474385058  |  0.023%\n",
      " 79    |  30.087352736930594  |  0.229%\n",
      "Total  |  13110.870968920943|  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal\")\n",
    "print_labels(divide_optimal_labels_train,opti_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen\n",
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  5268.0  |  32.555%\n",
      " 01    |  138.0   |  0.853%\n",
      " 02    |  840.0   |  5.191%\n",
      " 03    |  136.0   |  0.840%\n",
      " 04    |  88.0    |  0.544%\n",
      " 05    |  105.0   |  0.649%\n",
      " 06    |  75.0    |  0.463%\n",
      " 07    |  164.0   |  1.013%\n",
      " 08    |  173.0   |  1.069%\n",
      " 09    |  213.0   |  1.316%\n",
      " 10    |  33.0    |  0.204%\n",
      " 11    |  35.0    |  0.216%\n",
      " 12    |  23.0    |  0.142%\n",
      " 13    |  155.0   |  0.958%\n",
      " 14    |  172.0   |  1.063%\n",
      " 15    |  77.0    |  0.476%\n",
      " 16    |  96.0    |  0.593%\n",
      " 17    |  107.0   |  0.661%\n",
      " 18    |  150.0   |  0.927%\n",
      " 19    |  129.0   |  0.797%\n",
      " 20    |  92.0    |  0.569%\n",
      " 21    |  24.0    |  0.148%\n",
      " 22    |  90.0    |  0.556%\n",
      " 23    |  83.0    |  0.513%\n",
      " 24    |  176.0   |  1.088%\n",
      " 25    |  235.0   |  1.452%\n",
      " 26    |  269.0   |  1.662%\n",
      " 27    |  102.0   |  0.630%\n",
      " 28    |  108.0   |  0.667%\n",
      " 29    |  45.0    |  0.278%\n",
      " 30    |  108.0   |  0.667%\n",
      " 31    |  49.0    |  0.303%\n",
      " 32    |  100.0   |  0.618%\n",
      " 33    |  147.0   |  0.908%\n",
      " 34    |  57.0    |  0.352%\n",
      " 35    |  63.0    |  0.389%\n",
      " 36    |  93.0    |  0.575%\n",
      " 37    |  100.0   |  0.618%\n",
      " 38    |  84.0    |  0.519%\n",
      " 39    |  486.0   |  3.003%\n",
      " 40    |  164.0   |  1.013%\n",
      " 41    |  434.0   |  2.682%\n",
      " 42    |  109.0   |  0.674%\n",
      " 43    |  139.0   |  0.859%\n",
      " 44    |  116.0   |  0.717%\n",
      " 45    |  288.0   |  1.780%\n",
      " 46    |  154.0   |  0.952%\n",
      " 47    |  105.0   |  0.649%\n",
      " 48    |  72.0    |  0.445%\n",
      " 49    |  112.0   |  0.692%\n",
      " 50    |  114.0   |  0.704%\n",
      " 51    |  127.0   |  0.785%\n",
      " 52    |  49.0    |  0.303%\n",
      " 53    |  92.0    |  0.569%\n",
      " 54    |  112.0   |  0.692%\n",
      " 55    |  125.0   |  0.772%\n",
      " 56    |  838.0   |  5.179%\n",
      " 57    |  102.0   |  0.630%\n",
      " 58    |  137.0   |  0.847%\n",
      " 59    |  69.0    |  0.426%\n",
      " 60    |  293.0   |  1.811%\n",
      " 61    |  67.0    |  0.414%\n",
      " 62    |  97.0    |  0.599%\n",
      " 63    |  120.0   |  0.742%\n",
      " 64    |  38.0    |  0.235%\n",
      " 65    |  109.0   |  0.674%\n",
      " 66    |  50.0    |  0.309%\n",
      " 67    |  126.0   |  0.779%\n",
      " 68    |  31.0    |  0.192%\n",
      " 69    |  59.0    |  0.365%\n",
      " 70    |  8.0     |  0.049%\n",
      " 71    |  98.0    |  0.606%\n",
      " 72    |  46.0    |  0.284%\n",
      " 73    |  539.0   |  3.331%\n",
      " 74    |  100.0   |  0.618%\n",
      " 75    |  105.0   |  0.649%\n",
      " 76    |  28.0    |  0.173%\n",
      " 77    |  79.0    |  0.488%\n",
      " 78    |  7.0     |  0.043%\n",
      " 79    |  36.0    |  0.222%\n",
      "Total  |  16182.0 |  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"chosen\")\n",
    "print_labels(divide_chosen_labels_train,cho_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n",
      "[36, 49, 61, 77, 86, 109, 110, 113, 127, 149, 151, 165, 201, 260, 308, 315, 322, 326, 368, 370, 382, 389, 419, 431, 436, 443, 446, 471, 510, 529, 531, 532, 542, 572, 625, 634, 659, 673, 684, 690, 716, 722, 723, 731, 735, 781, 790, 795, 821, 828, 839, 882, 897, 901, 913, 925, 927, 934, 943, 960, 965, 984, 1006, 1011, 1014, 1053, 1098, 1102, 1107, 1108, 1144, 1145, 1183, 1200, 1204, 1216, 1232, 1237, 1271, 1295, 1298, 1307, 1308, 1311, 1315, 1319, 1330, 1332, 1350, 1359, 1360, 1375, 1381, 1390, 1397, 1401, 1403, 1407, 1424, 1431, 1451, 1453, 1488, 1523, 1527, 1536, 1548, 1569, 1579, 1580, 1586, 1596, 1637, 1639, 1670, 1706, 1720, 1732, 1756, 1762, 1764, 1774, 1785, 1790, 1804, 1811, 1815, 1822, 1837, 1864, 1875, 1888, 1895, 1900, 1911, 1915, 1924, 1941, 1942, 1943, 1947, 1958, 1966, 1994, 2001, 2007, 2055, 2056, 2072, 2083, 2089, 2114, 2135, 2184, 2211, 2229, 2258, 2278, 2281, 2337, 2369, 2372, 2377, 2400, 2402, 2415, 2444, 2445, 2446, 2459, 2466, 2470, 2498, 2536, 2543, 2555, 2560, 2563, 2567, 2575, 2583, 2585, 2602, 2614, 2639, 2644, 2658, 2664, 2672, 2686, 2687, 2691, 2693, 2703, 2732, 2742, 2752, 2754, 2755, 2758, 2774, 2782, 2823, 2833, 2842, 2860, 2892, 2896, 2907, 2951, 2963, 2983, 2992, 2998, 3000, 3008, 3048, 3076, 3077, 3118, 3124, 3157, 3160, 3197, 3220, 3225, 3236, 3242, 3272, 3276, 3293, 3320, 3325, 3348, 3353, 3361, 3365, 3366, 3375, 3412, 3432, 3457, 3461, 3478, 3493, 3514, 3521, 3528, 3532, 3535, 3538, 3579, 3602, 3628, 3637, 3685, 3713, 3735, 3751, 3770, 3804, 3827, 3830, 3860, 3870, 3897, 3911, 3915, 3917, 3920, 3967, 3988, 3995, 4020, 4042, 4065, 4080, 4129, 4130, 4131, 4138, 4139, 4140, 4159, 4172, 4173, 4180, 4201, 4219, 4239, 4244, 4259, 4289, 4309, 4331, 4360, 4376, 4377, 4385, 4404, 4421, 4424, 4428, 4441, 4442, 4478, 4489, 4490, 4502, 4508, 4527, 4535, 4549, 4555, 4567, 4574, 4578, 4587, 4595, 4608, 4616, 4642, 4662, 4684, 4702, 4704, 4711, 4714, 4716, 4739, 4741, 4823, 4834, 4843, 4844, 4859, 4876, 4891, 4893, 4903, 4947, 4968, 4981, 4984, 4993, 5016, 5018, 5021, 5028, 5073, 5083, 5085, 5086, 5094, 5113, 5131, 5139, 5140, 5152, 5156, 5165, 5169, 5172, 5198, 5210, 5215, 5219, 5256, 5260, 5288, 5294, 5303, 5312, 5313, 5324, 5336, 5339, 5360, 5368, 5373, 5376, 5377, 5424, 5425, 5430, 5459, 5471, 5482, 5483, 5505, 5508, 5559, 5587, 5589, 5608, 5614, 5619, 5620, 5632, 5638, 5641, 5683, 5684, 5688, 5689, 5699, 5701, 5715, 5736, 5740, 5756, 5769, 5811, 5823, 5828, 5882, 5883, 5906, 5915, 5916, 5917, 5933, 5946, 5962, 6004, 6010, 6026, 6031, 6041, 6042, 6051, 6053, 6057, 6075, 6101, 6107, 6140, 6148, 6151, 6155, 6190, 6200, 6216, 6225, 6233, 6253, 6262, 6268, 6287, 6293, 6295, 6318, 6327, 6332, 6334, 6338, 6339, 6357, 6358, 6364, 6379, 6380, 6407, 6409, 6414, 6421, 6424, 6432, 6465, 6489, 6491, 6517, 6520, 6522, 6531, 6539, 6541, 6562, 6572, 6578, 6590, 6602, 6603, 6627, 6632, 6640, 6664, 6675, 6692, 6709, 6710, 6715, 6744, 6747, 6749, 6760, 6764, 6777, 6780, 6790, 6811, 6824, 6846, 6860, 6862, 6873, 6901, 6920, 6935, 6941, 6943, 6945, 6957, 6964, 6973, 6981, 6996, 6998, 7035, 7049, 7069, 7103, 7104, 7116, 7123, 7124, 7129, 7159, 7167, 7201, 7221, 7228, 7232, 7275, 7277, 7307, 7318, 7357, 7420, 7424, 7452, 7500, 7503, 7524, 7535, 7539, 7583, 7594, 7596, 7603, 7615, 7621, 7623, 7627, 7629, 7642, 7650, 7653, 7685, 7689, 7710, 7727, 7733, 7735, 7746, 7757, 7758, 7782, 7794, 7809, 7819, 7830, 7838, 7839, 7853, 7894, 7921, 7932, 7946, 7953, 7988, 7996, 8014, 8019, 8024, 8025, 8043, 8053, 8055, 8058, 8063, 8066, 8074, 8086, 8095, 8106, 8114, 8176, 8186, 8187, 8238, 8284, 8285, 8294, 8297, 8305, 8309, 8314, 8321, 8329, 8339, 8341, 8369, 8383, 8396, 8414, 8422, 8429, 8432, 8436, 8458, 8468, 8494, 8504, 8519, 8520, 8536, 8553, 8571, 8581, 8587, 8592, 8593, 8630, 8639, 8649, 8653, 8657, 8659, 8677, 8725, 8746, 8747, 8772, 8781, 8794, 8807, 8809, 8813, 8816, 8821, 8829, 8834, 8836, 8841, 8846, 8856, 8872, 8896, 8909, 8933, 8944, 8965, 8968, 8979, 8991, 9012, 9018, 9024, 9025, 9029, 9045, 9057, 9095, 9112, 9133, 9138, 9190, 9202, 9203, 9218, 9226, 9253, 9296, 9322, 9372, 9408, 9409, 9429, 9446, 9451, 9460, 9462, 9465, 9469, 9488, 9514, 9542, 9556, 9557, 9608, 9615, 9648, 9651, 9656, 9658, 9669, 9696, 9698, 9708, 9738, 9744, 9745, 9760, 9767, 9771, 9774, 9789, 9797, 9820, 9833, 9836, 9845, 9846, 9859, 9872, 9878, 9885, 9895, 9910, 9929, 9935, 9946, 9951, 9960, 9968, 9983, 9987, 9990, 9993, 9999, 10005, 10015, 10024, 10041, 10069, 10082, 10094, 10097, 10130, 10175, 10176, 10179, 10230, 10232, 10239, 10243, 10244, 10245, 10265, 10275, 10281, 10309, 10313, 10318, 10319, 10321, 10342, 10358, 10388, 10434, 10445, 10472, 10498, 10545, 10560, 10579, 10581, 10600, 10614, 10621, 10624, 10639, 10646, 10683, 10689, 10701, 10710, 10711, 10727, 10732, 10743, 10784, 10787, 10799, 10817, 10818, 10831, 10870, 10871, 10877, 10881, 10890, 10925, 10929, 10948, 10969, 11004, 11015, 11025, 11029, 11041, 11065, 11075, 11077, 11091, 11107, 11129, 11138, 11158, 11159, 11168, 11195, 11223, 11227, 11229, 11231, 11233, 11238, 11256, 11258, 11264, 11265, 11271, 11272, 11282, 11288, 11292, 11304, 11326, 11328, 11332, 11349, 11358, 11401, 11402, 11403, 11411, 11426, 11461, 11487, 11497, 11544, 11569, 11576, 11579, 11591, 11613, 11619, 11624, 11631, 11638, 11658, 11661, 11673, 11677, 11680, 11690, 11701, 11702, 11713, 11720, 11737, 11754, 11774, 11775, 11791, 11794, 11801, 11802, 11805, 11826, 11849, 11953, 12044, 12154, 12155, 12307, 12313, 12345, 12398, 12839, 13144, 13292, 13302, 13318, 13325, 13650, 13720, 13815, 13909, 13912, 13916, 13944, 14138, 14180, 14238, 14261, 14312, 14367, 14375, 14432, 14458, 14628, 14764, 14768, 14876, 14886, 14938, 14988, 15071, 15354, 15374, 15379, 15472, 15617, 15859, 16072, 16101, 16112, 16246, 16273, 16346, 17236, 17399, 17481, 17587, 17717, 17866, 17985, 18059, 18316, 18333, 18460, 18482, 18513, 18555, 18564, 18641, 18658, 19123, 19134, 19374, 19385, 19448, 19929, 20030, 20046, 20202, 20255, 20391, 20421, 20456, 20489, 20601, 20707, 20768, 20769, 20888, 20929, 21003, 21020, 21083, 21320, 21364, 21447, 21451, 21462, 21469, 21528, 21571, 21632, 21647, 21740, 21782, 22026, 22102, 22149, 22198, 22256, 22278, 22281, 22298, 22367, 22374, 22907, 22953, 22954, 23134, 23137, 23255, 23274, 23419, 23544, 23569, 23695, 24150, 24154, 24234, 24520, 24699, 24714, 24730, 25017, 25237, 25665, 26662, 26745, 26764, 26988, 27282, 27451, 28287, 28728, 28797, 29712, 29801, 29931, 30693, 30803, 31010, 31157, 31334, 31335, 32700, 33009, 33017, 33111, 33425, 33429, 33959, 34279, 34340, 34525, 34732, 34795, 34854, 34884, 35004, 35156, 35190, 35322, 35367, 36292, 36326, 36345, 36574, 36652, 36823, 37011, 37122, 37230, 37697, 37862, 38026, 38055, 38274, 38396, 38440, 38622, 38900, 38933, 39321, 39446, 39447, 39553, 39588, 39987, 40796, 40884, 40923, 41284, 41630, 41678, 41742, 42007, 42105, 42277, 42285, 42384, 42418, 42476, 42740, 42799, 42804, 42849, 42868, 42972, 43029, 43093, 43269, 43560, 43683, 43892, 43912, 44668, 44704, 44734, 44741, 44751, 45459, 45701, 46004, 46152, 46242, 46315, 46634, 46764, 46813, 46883, 46965, 47172, 47194, 47406, 47599, 47652, 47680, 47949, 47983, 48001, 48165, 48267, 48381, 48451, 49625, 49640, 50518, 50536, 50597, 50725, 51550, 51774, 51791, 51795, 52305, 52324, 52437, 52628, 52747, 52951, 53108, 53111, 53640, 53641, 53643, 53793, 53939, 54111, 54341, 54837, 54893, 55402, 55468, 55707, 56134, 56145, 56240, 56442, 56664, 57339, 57926, 58172, 58241, 58405, 58547, 58640, 59046, 59151, 59335, 59573, 59691, 59693, 59735, 59870, 59918, 60513, 60820, 61307, 61527, 61635, 61675, 61683, 61849, 62046, 62770, 62850, 63325, 63409, 63485, 63553, 63676, 63764, 63866, 63875, 64389, 64622, 64802, 64962, 65166, 65247, 65329, 65836, 66299, 66734, 66767, 67256, 67786, 67802, 68075, 68502, 68633, 68685, 68717, 68748, 69401, 69523, 69777, 69809, 70122, 70387, 70745, 70758, 71528, 71792, 71907, 71911, 71970, 72007, 72120, 72535, 72583, 73016, 73064, 73196, 73260, 73434, 73936, 74348, 74686, 74887, 74900, 75084, 75119, 75496, 75811, 76244, 76492, 76607, 76802, 77557, 77721, 78075, 78447, 78494, 78542, 78923, 79077, 79421, 80818, 81057, 81143, 81323, 81612, 83548, 83619, 83979, 84218, 84427, 84479, 84512, 84839, 84964, 85462, 85728, 85790, 86031, 86210, 86217, 87058, 87555, 87610, 87655, 88274, 88538, 88575, 88621, 88697, 88744, 88759, 89101, 89481, 89571, 89906, 90509, 90612, 90862, 92054, 92420, 92480, 93427, 94353, 94608, 94841, 95133, 95320, 95390, 96046, 96064, 96202, 96586, 96808, 96973, 97029, 97173, 97504, 97564, 97569, 98008, 98276, 98345, 98564, 98733, 98752, 98944, 99066, 99311, 100523, 100591, 100798, 100959, 101038, 101069, 101074, 101084, 101522, 101572, 101632, 101807, 101894, 102149, 102205, 102278, 102877, 103042, 103486, 103773, 103927, 104125, 104510, 105058, 105063, 105172, 105374, 106363, 106498, 107351, 108113, 108266, 108442, 108510, 108536, 109334, 109357, 109561, 109635, 110707, 110811, 111245, 111330, 111455, 113442, 113979, 114678, 114718, 114869, 115569, 116123, 116126, 116134, 116792, 117182, 117300, 117307, 117494, 117555, 117684, 117691, 117721, 117918, 117931, 117958, 118485, 118697, 118870, 118881, 118904, 118918, 119529, 119614, 119714, 119751, 119798, 119860, 120276, 120778, 120782, 121302, 121420, 121530, 121575, 121665, 121693, 121824, 122097, 122207, 122238, 122303, 122573, 122731, 123229, 123445, 123974, 124182, 124419, 125015, 125115, 125227, 125429, 126021, 126073, 126090, 127072, 127559, 127945, 128076, 128113, 128137, 128395, 128608, 128736, 130037, 130065, 130163, 130286, 130324, 130538, 131107, 131126, 132249, 132290, 132746, 132760, 132781, 133278, 133295, 133384, 133565, 134238, 134755, 134782, 134832, 134937, 136002, 136184, 136338, 137110, 137339, 137365, 137704, 137824, 137890, 137892, 138027, 138103, 138148, 138747, 138891, 138961, 138982, 139111, 139120, 139211, 139285, 139416, 139748, 139787, 139970, 140044, 140067, 140322, 140432, 140481, 140581, 142016, 142287, 142393, 142557, 142601, 142656, 143758, 143845, 144147, 144915, 145006, 145161, 145348, 145444, 145460, 145915, 146583, 146656, 146819, 147192, 147291, 148859, 148986, 149180, 149388, 149423, 149498, 149657, 149817, 149833, 150354, 151403, 154060, 154140, 154443, 154650, 154659, 154754, 155735, 156323, 156506, 157186, 157204, 157251, 158058, 158810, 158897, 160115, 160625, 161937, 162031, 162055, 162319, 162322, 162712, 162937, 163615, 164553, 164786, 164891, 167559, 167827, 169330, 169883, 170008, 170931, 171175, 171239, 171284, 171472, 171536, 171758, 172158, 173069, 173882, 174930, 175336, 175672, 175881, 176174, 176461, 176479, 177109, 177807, 177832, 178426, 178491, 180522, 180578, 180911, 180968, 182112, 182189, 182416, 182658, 183224, 183268, 183453, 183829, 183913, 184209, 184679, 185233, 185326, 185519, 185571, 187025, 187654, 188552, 188587, 188623, 188688, 189017, 189071, 189156, 189670, 189741, 189789, 189847, 189880, 190026, 190187, 190486, 190547, 190981, 191188, 191293, 191686, 191690, 191957, 192577, 193025, 193623, 193760, 195288, 195797, 195969, 197237, 198108, 198137, 199427, 199502, 199720, 200181, 200728, 200796, 201940, 202447, 203021, 203940, 203975, 204174, 204333, 204732, 204826, 204863, 205121, 205279, 205380, 205564, 206058, 206731, 208067, 208146, 208244, 208845, 209068, 209292, 209802, 210086, 210702, 210791, 211570, 211641, 211644, 211686, 212118, 212941, 213268, 213423, 214450, 214587, 215135, 216091, 216304, 218113, 218379, 218503, 218513, 218868, 218980, 219117, 219355, 219418, 219756, 220654, 221427, 221532, 221691, 222074, 223006, 223089, 223330, 223477, 223577, 224224, 224246, 224499, 224833, 224929, 225667, 227003, 228045, 228329, 228334, 228336, 230428, 230522, 230548, 230601, 231874, 232005, 232417, 232689, 233224, 233955, 234839, 235351, 235906, 236632, 236740, 236823, 237003, 237233, 242116, 242721, 243580, 243645, 244014, 244442, 244712, 248133, 249382, 249455, 249555, 249587, 250162, 250385, 250708, 250768, 251049, 252000, 252105, 254520, 254706, 254795, 255271, 256082, 256608, 257666, 258364, 258501, 258566, 259030, 259120, 259198, 259338, 259464, 259491, 259498, 264618, 264712, 264888, 265355, 266334, 266336, 267289, 267548, 292512, 292763, 292928, 293524, 293679, 294349, 295159, 295257, 295550, 295803, 296760, 307379, 307708, 307814, 308473, 311563, 311564, 311773, 311957]\n"
     ]
    }
   ],
   "source": [
    "print(len(divide_file_number_train))\n",
    "print(divide_file_number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#copy files chosen update logs\n",
    "create_divide_dataset(divide_file_number_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#get full val labels\n",
    "\n",
    "all_labels_number_val,all_labels_percentage_val,nbtotfile_val=get_all_labels(val=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40137\n"
     ]
    }
   ],
   "source": [
    "#update nb of file\n",
    "nb_file_val=nbtotfile_val\n",
    "print(nb_file_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  86348   |  29.939%\n",
      " 01    |  2458    |  0.852%\n",
      " 02    |  14898   |  5.165%\n",
      " 03    |  3049    |  1.057%\n",
      " 04    |  1444    |  0.501%\n",
      " 05    |  2023    |  0.701%\n",
      " 06    |  1602    |  0.555%\n",
      " 07    |  3337    |  1.157%\n",
      " 08    |  3543    |  1.228%\n",
      " 09    |  4351    |  1.509%\n",
      " 10    |  650     |  0.225%\n",
      " 11    |  686     |  0.238%\n",
      " 12    |  510     |  0.177%\n",
      " 13    |  3490    |  1.210%\n",
      " 14    |  3852    |  1.336%\n",
      " 15    |  1669    |  0.579%\n",
      " 16    |  1951    |  0.676%\n",
      " 17    |  2187    |  0.758%\n",
      " 18    |  3119    |  1.081%\n",
      " 19    |  2788    |  0.967%\n",
      " 20    |  1856    |  0.644%\n",
      " 21    |  462     |  0.160%\n",
      " 22    |  1877    |  0.651%\n",
      " 23    |  1767    |  0.613%\n",
      " 24    |  2890    |  1.002%\n",
      " 25    |  3919    |  1.359%\n",
      " 26    |  4113    |  1.426%\n",
      " 27    |  2234    |  0.775%\n",
      " 28    |  2219    |  0.769%\n",
      " 29    |  935     |  0.324%\n",
      " 30    |  2180    |  0.756%\n",
      " 31    |  793     |  0.275%\n",
      " 32    |  2198    |  0.762%\n",
      " 33    |  2770    |  0.960%\n",
      " 34    |  1020    |  0.354%\n",
      " 35    |  1206    |  0.418%\n",
      " 36    |  1705    |  0.591%\n",
      " 37    |  2227    |  0.772%\n",
      " 38    |  1626    |  0.564%\n",
      " 39    |  8282    |  2.872%\n",
      " 40    |  2620    |  0.908%\n",
      " 41    |  7010    |  2.431%\n",
      " 42    |  1775    |  0.615%\n",
      " 43    |  2555    |  0.886%\n",
      " 44    |  2130    |  0.739%\n",
      " 45    |  4903    |  1.700%\n",
      " 46    |  2854    |  0.990%\n",
      " 47    |  1761    |  0.611%\n",
      " 48    |  1457    |  0.505%\n",
      " 49    |  2057    |  0.713%\n",
      " 50    |  2679    |  0.929%\n",
      " 51    |  2646    |  0.917%\n",
      " 52    |  1009    |  0.350%\n",
      " 53    |  2097    |  0.727%\n",
      " 54    |  2474    |  0.858%\n",
      " 55    |  2097    |  0.727%\n",
      " 56    |  12987   |  4.503%\n",
      " 57    |  1927    |  0.668%\n",
      " 58    |  3069    |  1.064%\n",
      " 59    |  1450    |  0.503%\n",
      " 60    |  5237    |  1.816%\n",
      " 61    |  1462    |  0.507%\n",
      " 62    |  2057    |  0.713%\n",
      " 63    |  1781    |  0.618%\n",
      " 64    |  850     |  0.295%\n",
      " 65    |  1863    |  0.646%\n",
      " 66    |  1028    |  0.356%\n",
      " 67    |  2233    |  0.774%\n",
      " 68    |  539     |  0.187%\n",
      " 69    |  1175    |  0.407%\n",
      " 70    |  78      |  0.027%\n",
      " 71    |  1901    |  0.659%\n",
      " 72    |  888     |  0.308%\n",
      " 73    |  8342    |  2.892%\n",
      " 74    |  2271    |  0.787%\n",
      " 75    |  2251    |  0.780%\n",
      " 76    |  441     |  0.153%\n",
      " 77    |  1522    |  0.528%\n",
      " 78    |  74      |  0.026%\n",
      " 79    |  630     |  0.218%\n",
      "Total  |  288414  |  100.0%\n"
     ]
    }
   ],
   "source": [
    "#print full val labels\n",
    "print_labels(all_labels_number_val,all_labels_percentage_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for val dataset : chose files for balance reduced dataset\n",
    "\n",
    "divide_file_number_val, divide_optimal_labels_val, divide_chosen_labels_val = divide_dataset(all_labels_number_val,all_labels_percentage_val,val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_op_val=np.sum(divide_optimal_labels_val)\n",
    "tot_cho_val=np.sum(divide_chosen_labels_val)\n",
    "opti_perc_val=divide_optimal_labels_val/tot_op_val\n",
    "cho_perc_val=np.copy(divide_chosen_labels_val)\n",
    "cho_perc_val=cho_perc_val.astype(\"float64\")\n",
    "cho_perc_val/=tot_cho_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  430.26633779305877  |  29.939%\n",
      " 01    |  12.248050427286543  |  0.852%\n",
      " 02    |  74.23574258165782  |  5.165%\n",
      " 03    |  15.192964097964472  |  1.057%\n",
      " 04    |  7.1953559060218755  |  0.501%\n",
      " 05    |  10.080474375264718  |  0.701%\n",
      " 06    |  7.982659391583826  |  0.555%\n",
      " 07    |  16.628048932406507  |  1.157%\n",
      " 08    |  17.654533223708796  |  1.228%\n",
      " 09    |  21.680743453671177  |  1.509%\n",
      " 10    |  3.2389067444004285  |  0.225%\n",
      " 11    |  3.418292348705683  |  0.238%\n",
      " 12    |  2.5412960609911055  |  0.177%\n",
      " 13    |  17.39043775070384  |  1.210%\n",
      " 14    |  19.194259660662233  |  1.336%\n",
      " 15    |  8.316515932929716  |  0.579%\n",
      " 16    |  9.72170316665421  |  0.676%\n",
      " 17    |  10.89767546154421  |  0.758%\n",
      " 18    |  15.541769439669133  |  1.081%\n",
      " 19    |  13.892418466751376  |  0.967%\n",
      " 20    |  9.248324488626455  |  0.644%\n",
      " 21    |  2.302115255250766  |  0.160%\n",
      " 22    |  9.352966091137853  |  0.651%\n",
      " 23    |  8.804843411316241  |  0.613%\n",
      " 24    |  14.400677678949597  |  1.002%\n",
      " 25    |  19.52811620200812  |  1.359%\n",
      " 26    |  20.494805291875327  |  1.426%\n",
      " 27    |  11.131873333831626  |  0.775%\n",
      " 28    |  11.057129332037771  |  0.769%\n",
      " 29    |  4.659042778483693  |  0.324%\n",
      " 30    |  10.862794927373745  |  0.756%\n",
      " 31    |  3.9514662281685227  |  0.275%\n",
      " 32    |  10.952487729526371  |  0.762%\n",
      " 33    |  13.80272566459875  |  0.960%\n",
      " 34    |  5.082592121982211  |  0.354%\n",
      " 35    |  6.009417744226026  |  0.418%\n",
      " 36    |  8.495901537234971  |  0.591%\n",
      " 37    |  11.09699279966116  |  0.772%\n",
      " 38    |  8.102249794453995  |  0.564%\n",
      " 39    |  41.268654857114385  |  2.872%\n",
      " 40    |  13.055285646660188  |  0.908%\n",
      " 41    |  34.93036350499539  |  2.431%\n",
      " 42    |  8.844706878939633  |  0.615%\n",
      " 43    |  12.731394972220146  |  0.886%\n",
      " 44    |  10.613648254727558  |  0.739%\n",
      " 45    |  24.431322719685078  |  1.700%\n",
      " 46    |  14.221292074644342  |  0.990%\n",
      " 47    |  8.7749458105987  |  0.611%\n",
      " 48    |  7.260134040909883  |  0.505%\n",
      " 49    |  10.249894112664125  |  0.713%\n",
      " 50    |  13.349278720382689  |  0.929%\n",
      " 51    |  13.184841916436206  |  0.917%\n",
      " 52    |  5.02777985400005  |  0.350%\n",
      " 53    |  10.449211450781075  |  0.727%\n",
      " 54    |  12.327777362533324  |  0.858%\n",
      " 55    |  10.449211450781075  |  0.727%\n",
      " 56    |  64.71335675312056  |  4.503%\n",
      " 57    |  9.60211276378404  |  0.668%\n",
      " 58    |  15.292622767022946  |  1.064%\n",
      " 59    |  7.225253506739418  |  0.503%\n",
      " 60    |  26.095622492961606  |  1.816%\n",
      " 61    |  7.285048708174502  |  0.507%\n",
      " 62    |  10.249894112664125  |  0.713%\n",
      " 63    |  8.874604479657174  |  0.618%\n",
      " 64    |  4.235493434985176  |  0.295%\n",
      " 65    |  9.28320502279692  |  0.646%\n",
      " 66    |  5.122455589605601  |  0.356%\n",
      " 67    |  11.126890400378702  |  0.774%\n",
      " 68    |  2.685801131125894  |  0.187%\n",
      " 69    |  5.85494680718539  |  0.407%\n",
      " 70    |  0.3886688093280514  |  0.027%\n",
      " 71    |  9.472556494008023  |  0.659%\n",
      " 72    |  4.424844906196277  |  0.308%\n",
      " 73    |  41.56763086428981  |  2.892%\n",
      " 74    |  11.316241871589805  |  0.787%\n",
      " 75    |  11.21658320253133  |  0.780%\n",
      " 76    |  2.1974736527393675  |  0.153%\n",
      " 77    |  7.584024715349926  |  0.528%\n",
      " 78    |  0.3687370755163565  |  0.026%\n",
      " 79    |  3.139248075341954  |  0.218%\n",
      "Total  |  1437.1477688915465|  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal\")\n",
    "print_labels(divide_optimal_labels_val,opti_perc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen\n",
      "Label  |  Number  |  Percentage\n",
      "_______________________________\n",
      " 00    |  534.0   |  29.983%\n",
      " 01    |  11.0    |  0.618%\n",
      " 02    |  92.0    |  5.166%\n",
      " 03    |  24.0    |  1.348%\n",
      " 04    |  5.0     |  0.281%\n",
      " 05    |  9.0     |  0.505%\n",
      " 06    |  7.0     |  0.393%\n",
      " 07    |  21.0    |  1.179%\n",
      " 08    |  21.0    |  1.179%\n",
      " 09    |  32.0    |  1.797%\n",
      " 10    |  1.0     |  0.056%\n",
      " 11    |  2.0     |  0.112%\n",
      " 12    |  0.0     |  0.000%\n",
      " 13    |  20.0    |  1.123%\n",
      " 14    |  44.0    |  2.471%\n",
      " 15    |  6.0     |  0.337%\n",
      " 16    |  7.0     |  0.393%\n",
      " 17    |  10.0    |  0.561%\n",
      " 18    |  14.0    |  0.786%\n",
      " 19    |  13.0    |  0.730%\n",
      " 20    |  7.0     |  0.393%\n",
      " 21    |  0.0     |  0.000%\n",
      " 22    |  8.0     |  0.449%\n",
      " 23    |  6.0     |  0.337%\n",
      " 24    |  13.0    |  0.730%\n",
      " 25    |  19.0    |  1.067%\n",
      " 26    |  26.0    |  1.460%\n",
      " 27    |  14.0    |  0.786%\n",
      " 28    |  12.0    |  0.674%\n",
      " 29    |  4.0     |  0.225%\n",
      " 30    |  11.0    |  0.618%\n",
      " 31    |  4.0     |  0.225%\n",
      " 32    |  12.0    |  0.674%\n",
      " 33    |  19.0    |  1.067%\n",
      " 34    |  8.0     |  0.449%\n",
      " 35    |  13.0    |  0.730%\n",
      " 36    |  17.0    |  0.955%\n",
      " 37    |  10.0    |  0.561%\n",
      " 38    |  10.0    |  0.561%\n",
      " 39    |  47.0    |  2.639%\n",
      " 40    |  26.0    |  1.460%\n",
      " 41    |  56.0    |  3.144%\n",
      " 42    |  13.0    |  0.730%\n",
      " 43    |  19.0    |  1.067%\n",
      " 44    |  24.0    |  1.348%\n",
      " 45    |  31.0    |  1.741%\n",
      " 46    |  14.0    |  0.786%\n",
      " 47    |  13.0    |  0.730%\n",
      " 48    |  5.0     |  0.281%\n",
      " 49    |  10.0    |  0.561%\n",
      " 50    |  18.0    |  1.011%\n",
      " 51    |  18.0    |  1.011%\n",
      " 52    |  15.0    |  0.842%\n",
      " 53    |  12.0    |  0.674%\n",
      " 54    |  10.0    |  0.561%\n",
      " 55    |  20.0    |  1.123%\n",
      " 56    |  101.0   |  5.671%\n",
      " 57    |  10.0    |  0.561%\n",
      " 58    |  15.0    |  0.842%\n",
      " 59    |  5.0     |  0.281%\n",
      " 60    |  38.0    |  2.134%\n",
      " 61    |  5.0     |  0.281%\n",
      " 62    |  10.0    |  0.561%\n",
      " 63    |  10.0    |  0.561%\n",
      " 64    |  6.0     |  0.337%\n",
      " 65    |  11.0    |  0.618%\n",
      " 66    |  5.0     |  0.281%\n",
      " 67    |  16.0    |  0.898%\n",
      " 68    |  2.0     |  0.112%\n",
      " 69    |  5.0     |  0.281%\n",
      " 70    |  0.0     |  0.000%\n",
      " 71    |  7.0     |  0.393%\n",
      " 72    |  5.0     |  0.281%\n",
      " 73    |  57.0    |  3.200%\n",
      " 74    |  9.0     |  0.505%\n",
      " 75    |  17.0    |  0.955%\n",
      " 76    |  1.0     |  0.056%\n",
      " 77    |  6.0     |  0.337%\n",
      " 78    |  0.0     |  0.000%\n",
      " 79    |  3.0     |  0.168%\n",
      "Total  |  1781.0  |  100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"chosen\")\n",
    "print_labels(divide_chosen_labels_val,cho_perc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[74, 136, 139, 192, 241, 257, 294, 328, 338, 357, 360, 395, 397, 415, 428, 459, 474, 488, 520, 536, 544, 564, 569, 589, 623, 641, 692, 693, 730, 761, 764, 785, 810, 831, 836, 872, 885, 923, 962, 969, 974, 985, 999, 1000, 1089, 1146, 1149, 1164, 1176, 1180, 1244, 1268, 1270, 1290, 1292, 1296, 1342, 1353, 1369, 1398, 1404, 1436, 1464, 1490, 1554, 1563, 1584, 1591, 1592, 1599, 1626, 1655, 1667, 1668, 1700, 1722, 1757, 1761, 1799, 1841, 1856, 1948, 1955, 1960, 1987, 2006, 2014, 2124, 2142, 2153, 2154, 2171, 2179, 2191, 2225, 2235, 2239, 2261, 2529, 2532, 2562, 2640, 2822, 2890, 2985, 3145, 3337, 3590, 3595, 3711, 3817, 3849, 3934, 4108, 4916, 5595, 5802, 6608, 6701, 7214, 7297, 8583, 8718, 8762, 8922, 9186, 9274, 9527, 9590, 10785, 11172, 11198, 12062, 12153, 14733, 15278, 18928, 19358, 19723, 19904, 20381, 20395, 20608, 20837, 21614, 22870, 25316, 25595, 26209, 26432, 26445, 26564, 28463, 29253, 29484, 30213, 31596, 32056, 32082, 32597, 32817, 34212, 35474, 35599, 35672, 35952, 36311, 36522, 36942, 37670, 38092, 38875, 38919, 40102, 42225, 42889, 43758, 43771, 44054, 44524, 46428, 46877, 47225, 48972, 49133, 51495, 51976, 52637, 53434, 53958, 54520, 54598, 54603, 54870, 56137, 56205, 57879, 60849, 61566, 62220]\n"
     ]
    }
   ],
   "source": [
    "print(len(divide_file_number_val))\n",
    "print(divide_file_number_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#copy files chosen update logs\n",
    "create_divide_dataset(divide_file_number_val, val=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
